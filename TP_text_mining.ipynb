{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50576081",
   "metadata": {},
   "source": [
    "# TP Text Mining \n",
    "\n",
    "## Charger le jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "71e264fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      If only people would just take a step back and...\n",
      "1      Law enforcement is not trained to shoot to app...\n",
      "2      \\nDont you reckon them 'black lives matter' ba...\n",
      "3      There are a very large number of people who do...\n",
      "4      The Arab dude is absolutely right, he should h...\n",
      "                             ...                        \n",
      "995    I remember that they sent in the national defe...\n",
      "996    Stats don`t represent the problem. Race baitin...\n",
      "997    The quote from the mother... Wow that hit hard...\n",
      "998                              this video is so racist\n",
      "999        God, the narrator has such an annoying lisp. \n",
      "Name: Text, Length: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('youtoxic_english_1000.csv')\n",
    "df.head()\n",
    "print(df[\"Text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc35a04",
   "metadata": {},
   "source": [
    "# Nettoyage du texte\n",
    "\n",
    "## suppression de ponctuation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ca091dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      if only people would just take a step back and...\n",
      "1      law enforcement is not trained to shoot to app...\n",
      "2      \\ndont you reckon them black lives matter bann...\n",
      "3      there are a very large number of people who do...\n",
      "4      the arab dude is absolutely right he should ha...\n",
      "                             ...                        \n",
      "995    i remember that they sent in the national defe...\n",
      "996    stats dont represent the problem race baiting ...\n",
      "997    the quote from the mother wow that hit hard ve...\n",
      "998                              this video is so racist\n",
      "999          god the narrator has such an annoying lisp \n",
      "Name: Text, Length: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    return text\n",
    "\n",
    "text= df['Text'].apply(remove_punctuation)\n",
    "print(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c18680d",
   "metadata": {},
   "source": [
    "## Convertir en minuscules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "763d881c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      if only people would just take a step back and...\n",
      "1      law enforcement is not trained to shoot to app...\n",
      "2      \\ndont you reckon them black lives matter bann...\n",
      "3      there are a very large number of people who do...\n",
      "4      the arab dude is absolutely right he should ha...\n",
      "                             ...                        \n",
      "995    i remember that they sent in the national defe...\n",
      "996    stats dont represent the problem race baiting ...\n",
      "997    the quote from the mother wow that hit hard ve...\n",
      "998                              this video is so racist\n",
      "999          god the narrator has such an annoying lisp \n",
      "Name: Text, Length: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_to_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "text1 = text.apply(convert_to_lowercase)\n",
    "print(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc34070",
   "metadata": {},
   "source": [
    "## Suppression des mots vides\n",
    "\n",
    "Suppression des mots vides à l'aide d'une liste de mots vides standard disponible dans NLTK pour l'anglais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ad751804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      people would take step back make case wasnt an...\n",
      "1      law enforcement trained shoot apprehend traine...\n",
      "2      dont reckon black lives matter banners held wh...\n",
      "3      large number people like police officers calle...\n",
      "4      arab dude absolutely right shot 6 extra time s...\n",
      "                             ...                        \n",
      "995                       remember sent national defence\n",
      "996    stats dont represent problem race baiting atti...\n",
      "997                   quote mother wow hit hard accurate\n",
      "998                                         video racist\n",
      "999                           god narrator annoying lisp\n",
      "Name: Text, Length: 1000, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\x1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
    "    return text\n",
    "\n",
    "text2 = text1.apply(remove_stopwords)\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bd31ae",
   "metadata": {},
   "source": [
    "## supprimer les liens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "719f41a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      people would take step back make case wasnt an...\n",
      "1      law enforcement trained shoot apprehend traine...\n",
      "2      dont reckon black lives matter banners held wh...\n",
      "3      large number people like police officers calle...\n",
      "4      arab dude absolutely right shot 6 extra time s...\n",
      "                             ...                        \n",
      "995                       remember sent national defence\n",
      "996    stats dont represent problem race baiting atti...\n",
      "997                   quote mother wow hit hard accurate\n",
      "998                                         video racist\n",
      "999                           god narrator annoying lisp\n",
      "Name: Text, Length: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def remove_urls(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'www\\S+', '', text)\n",
    "    return text\n",
    "\n",
    "text3 = text2.apply(remove_urls)\n",
    "print(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f422aeb7",
   "metadata": {},
   "source": [
    "## supprimer les nombres "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a34b9447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      people would take step back make case wasnt an...\n",
      "1      law enforcement trained shoot apprehend traine...\n",
      "2      dont reckon black lives matter banners held wh...\n",
      "3      large number people like police officers calle...\n",
      "4      arab dude absolutely right shot  extra time sh...\n",
      "                             ...                        \n",
      "995                       remember sent national defence\n",
      "996    stats dont represent problem race baiting atti...\n",
      "997                   quote mother wow hit hard accurate\n",
      "998                                         video racist\n",
      "999                           god narrator annoying lisp\n",
      "Name: Text, Length: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_numbers(text):\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    return text\n",
    "\n",
    "text4=text3.apply(remove_numbers)\n",
    "print(text4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad22f98",
   "metadata": {},
   "source": [
    " ## Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "94e65691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      people would take step back make case wasnt an...\n",
      "1      law enforcement trained shoot apprehend traine...\n",
      "2      dont reckon black life matter banner held whit...\n",
      "3      large number people like police officer called...\n",
      "4      arab dude absolutely right shot extra time sho...\n",
      "                             ...                        \n",
      "995                       remember sent national defence\n",
      "996    stats dont represent problem race baiting atti...\n",
      "997                   quote mother wow hit hard accurate\n",
      "998                                         video racist\n",
      "999                           god narrator annoying lisp\n",
      "Name: Text, Length: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "text5 = text4.apply(lemmatize_text)\n",
    "print(text5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7282f9a",
   "metadata": {},
   "source": [
    "##  Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4a10411c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      [people, would, take, step, back, make, case, ...\n",
      "1      [law, enforcement, trained, shoot, apprehend, ...\n",
      "2      [dont, reckon, black, lives, matter, banners, ...\n",
      "3      [large, number, people, like, police, officers...\n",
      "4      [arab, dude, absolutely, right, shot, extra, t...\n",
      "                             ...                        \n",
      "995                  [remember, sent, national, defence]\n",
      "996    [stats, dont, represent, problem, race, baitin...\n",
      "997            [quote, mother, wow, hit, hard, accurate]\n",
      "998                                      [video, racist]\n",
      "999                      [god, narrator, annoying, lisp]\n",
      "Name: Text, Length: 1000, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\x1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "text5 = text4.apply(tokenize_text)\n",
    "print(text5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
